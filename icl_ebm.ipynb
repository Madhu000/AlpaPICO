{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7a282-b392-43bb-8a37-24c8eb1657f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-29T17:54:11.806860Z",
     "iopub.status.busy": "2023-10-29T17:54:11.806288Z"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26dde51f-08e9-4ba3-93f4-72083ab416df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:18:51.935964Z",
     "iopub.status.busy": "2023-11-01T15:18:51.935698Z",
     "iopub.status.idle": "2023-11-01T15:18:56.818493Z",
     "shell.execute_reply": "2023-11-01T15:18:56.817633Z",
     "shell.execute_reply.started": "2023-11-01T15:18:51.935945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e1af1a-6704-4b83-b26c-b227dca6ae74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:19:23.783022Z",
     "iopub.status.busy": "2023-11-01T15:19:23.782210Z",
     "iopub.status.idle": "2023-11-01T15:19:24.779381Z",
     "shell.execute_reply": "2023-11-01T15:19:24.778725Z",
     "shell.execute_reply.started": "2023-11-01T15:19:23.782999Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# import faiss\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7149214c-9675-465b-ad5a-faa9b7e19610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:19:26.183462Z",
     "iopub.status.busy": "2023-11-01T15:19:26.183122Z",
     "iopub.status.idle": "2023-11-01T15:19:26.410592Z",
     "shell.execute_reply": "2023-11-01T15:19:26.410062Z",
     "shell.execute_reply.started": "2023-11-01T15:19:26.183442Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40935/40935 [00:00<00:00, 213174.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "with open(\"/notebooks/NER/instruct-ner/ebmnlp_hf/train.json\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        j = json.loads(line)\n",
    "        d = \" \".join(j['tokens'])\n",
    "        train_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a4b6e6-9c1a-4f7c-9bb4-109c11e9ca21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:19:28.800975Z",
     "iopub.status.busy": "2023-11-01T15:19:28.800709Z",
     "iopub.status.idle": "2023-11-01T15:19:37.292950Z",
     "shell.execute_reply": "2023-11-01T15:19:37.292284Z",
     "shell.execute_reply.started": "2023-11-01T15:19:28.800955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad172aa711d4f949e904c4bb637b6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f260d920a332433fb15926534734efc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3fdf9e0aa648168f3df3df693f39bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/221k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff65e23efa3b4fa8a6c03ad88d643636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext',model_max_length=512)\n",
    "model = AutoModel.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')\n",
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d251fc38-01b6-4a2b-969a-3001f1cad8fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:19:42.066801Z",
     "iopub.status.busy": "2023-11-01T15:19:42.065968Z",
     "iopub.status.idle": "2023-11-01T15:25:52.595507Z",
     "shell.execute_reply": "2023-11-01T15:25:52.593905Z",
     "shell.execute_reply.started": "2023-11-01T15:19:42.066768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40935/40935 [06:10<00:00, 110.48it/s]\n"
     ]
    }
   ],
   "source": [
    "full_embd = []\n",
    "for data in tqdm(train_data):\n",
    "    tokenized_sents = tokenizer(data, return_tensors='pt', padding=True, truncation=True).to(\"cuda:0\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**tokenized_sents)[0]\n",
    "\n",
    "    cls_emb = last_hidden_state[:, 0, :].squeeze(0).cpu().numpy().reshape(1,-1)\n",
    "    # print(cls_emb.shape)\n",
    "    faiss.normalize_L2(cls_emb)\n",
    "    full_embd.append(cls_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f603d7b9-659d-4de7-ba4e-bd8c3e540bdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T13:44:55.679607Z",
     "iopub.status.busy": "2023-10-31T13:44:55.678658Z",
     "iopub.status.idle": "2023-10-31T13:44:56.412000Z",
     "shell.execute_reply": "2023-10-31T13:44:56.411270Z",
     "shell.execute_reply.started": "2023-10-31T13:44:55.679578Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/notebooks/prompt_pico/scirex/ICL/Emb/train_index_embd.pkl\",\"wb\") as f:\n",
    "    pkl.dump(full_embd,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b9f01b-5a9f-42ef-a64c-fe221cee5808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:28:55.085139Z",
     "iopub.status.busy": "2023-11-01T15:28:55.084522Z",
     "iopub.status.idle": "2023-11-01T15:28:55.154800Z",
     "shell.execute_reply": "2023-11-01T15:28:55.154111Z",
     "shell.execute_reply.started": "2023-11-01T15:28:55.085117Z"
    }
   },
   "outputs": [],
   "source": [
    "full_embd_cat = np.concatenate(full_embd,axis=0)\n",
    "# full_embd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d075a51c-5b85-4863-8eb4-1e8f97d8002a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:28:56.597757Z",
     "iopub.status.busy": "2023-11-01T15:28:56.597033Z",
     "iopub.status.idle": "2023-11-01T15:28:56.603125Z",
     "shell.execute_reply": "2023-11-01T15:28:56.602202Z",
     "shell.execute_reply.started": "2023-11-01T15:28:56.597723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40935, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_embd_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4340538b-3da0-4a88-be0f-7298812f8d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:28:58.038410Z",
     "iopub.status.busy": "2023-11-01T15:28:58.037746Z",
     "iopub.status.idle": "2023-11-01T15:28:58.041528Z",
     "shell.execute_reply": "2023-11-01T15:28:58.041029Z",
     "shell.execute_reply.started": "2023-11-01T15:28:58.038388Z"
    }
   },
   "outputs": [],
   "source": [
    "# for data in \n",
    "\n",
    "    \n",
    "# quantizer = faiss.IndexFlatL2(768)\n",
    "# index = faiss.IndexIVFFlat(quantizer, 768, 18, faiss.METRIC_L2)\n",
    "# index.train(last_hidden_state.squeeze(0).cpu().numpy())\n",
    "\n",
    "# faiss.normalize_L2(full_embd_cat)\n",
    "index = faiss.index_factory(768, \"Flat\", 0)\n",
    "index.train(full_embd_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a40253-37fe-4e61-89b8-3d2520b3313a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:29:00.363514Z",
     "iopub.status.busy": "2023-11-01T15:29:00.363140Z",
     "iopub.status.idle": "2023-11-01T15:29:00.432894Z",
     "shell.execute_reply": "2023-11-01T15:29:00.432357Z",
     "shell.execute_reply.started": "2023-11-01T15:29:00.363493Z"
    }
   },
   "outputs": [],
   "source": [
    "index.add(full_embd_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9344c7-1938-4297-b563-bfac0ac88d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T15:29:12.107730Z",
     "iopub.status.busy": "2023-11-01T15:29:12.107171Z",
     "iopub.status.idle": "2023-11-01T15:29:12.175581Z",
     "shell.execute_reply": "2023-11-01T15:29:12.174919Z",
     "shell.execute_reply.started": "2023-11-01T15:29:12.107707Z"
    }
   },
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"/notebooks/NER/instruct-ner/ebmnlp_hf/train_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9722053a-b02e-427d-a503-59c981054866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T12:25:36.192741Z",
     "iopub.status.busy": "2023-11-01T12:25:36.191769Z",
     "iopub.status.idle": "2023-11-01T12:25:36.281867Z",
     "shell.execute_reply": "2023-11-01T12:25:36.281353Z",
     "shell.execute_reply.started": "2023-11-01T12:25:36.192715Z"
    }
   },
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"/notebooks/NER/instruct-ner/ebmnlp_hr_hf/train_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dec2f70-b75d-483b-8592-dafe5c27a38d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T06:49:35.412354Z",
     "iopub.status.busy": "2023-10-27T06:49:35.411670Z",
     "iopub.status.idle": "2023-10-27T06:49:36.104311Z",
     "shell.execute_reply": "2023-10-27T06:49:36.103461Z",
     "shell.execute_reply.started": "2023-10-27T06:49:35.412327Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong number or type of arguments for overloaded function 'new_IndexFlatL2'.\n  Possible C/C++ prototypes are:\n    faiss::IndexFlatL2::IndexFlatL2(faiss::Index::idx_t)\n    faiss::IndexFlatL2::IndexFlatL2()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quantizer \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexFlatL2\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/faiss/swigfaiss.py:2204\u001b[0m, in \u001b[0;36mIndexFlatL2.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 2204\u001b[0m     _swigfaiss\u001b[38;5;241m.\u001b[39mIndexFlatL2_swiginit(\u001b[38;5;28mself\u001b[39m, \u001b[43m_swigfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_IndexFlatL2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Wrong number or type of arguments for overloaded function 'new_IndexFlatL2'.\n  Possible C/C++ prototypes are:\n    faiss::IndexFlatL2::IndexFlatL2(faiss::Index::idx_t)\n    faiss::IndexFlatL2::IndexFlatL2()\n"
     ]
    }
   ],
   "source": [
    "def create_index_faiss(path):\n",
    "    # print(sentence)\n",
    "    f=open(path,'r')\n",
    "    sent=normalize(f.read())\n",
    "    # print(sent)\n",
    "    tokenized_sents = tokenizer(sent, return_tensors='pt', padding=True, truncation=True).to(\"cuda:0\")\n",
    "    # print(tokenized_sents)\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**tokenized_sents)[0]\n",
    "\n",
    "    cls_emb = last_hidden_state[:, 0, :]\n",
    "    cls_emb_1=cls_emb.cpu().numpy()\n",
    "    faiss.normalize_L2(cls_emb_1)\n",
    "    index.add(cls_emb_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a586fa-cc98-4e5b-b6e0-1ce198719b34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:12:10.623888Z",
     "iopub.status.busy": "2023-10-30T16:12:10.623337Z",
     "iopub.status.idle": "2023-10-30T16:12:10.649669Z",
     "shell.execute_reply": "2023-10-30T16:12:10.649151Z",
     "shell.execute_reply.started": "2023-10-30T16:12:10.623865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1658/1658 [00:00<00:00, 190113.34it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "with open(\"/notebooks/Cods_PICO/instruct-ner/ebm_rev_hf/test.json\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        j = json.loads(line)\n",
    "        d = \" \".join(j['tokens'])\n",
    "        test_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec2102d7-6f0f-42fa-bf25-d58a5d7c2209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:12:29.648269Z",
     "iopub.status.busy": "2023-10-30T16:12:29.647753Z",
     "iopub.status.idle": "2023-10-30T16:12:29.914304Z",
     "shell.execute_reply": "2023-10-30T16:12:29.913553Z",
     "shell.execute_reply.started": "2023-10-30T16:12:29.648247Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/notebooks/Cods_PICO/instruct-ner/instruction_ner/ebm_rev_dataset/train.pkl\",\"rb\") as f:\n",
    "    f_train = pkl.load(f)\n",
    "\n",
    "with open(\"/notebooks/Cods_PICO/instruct-ner/instruction_ner/ebm_rev_dataset/test.pkl\",\"rb\") as f:\n",
    "    f_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5383a13-5265-418b-85d1-82e4b18b9e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T11:49:59.456112Z",
     "iopub.status.busy": "2023-10-27T11:49:59.455564Z",
     "iopub.status.idle": "2023-10-27T11:49:59.460351Z",
     "shell.execute_reply": "2023-10-27T11:49:59.459679Z",
     "shell.execute_reply.started": "2023-10-27T11:49:59.456087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       " 'input': 'Comparison of budesonide Turbuhaler with budesonide aqua in the treatment of seasonal allergic rhinitis .',\n",
       " 'output': 'INT: budesonide Turbuhaler, budesonide aqua\\nPAR: seasonal allergic rhinitis .\\nOUT: \\n',\n",
       " 'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of budesonide Turbuhaler with budesonide aqua in the treatment of seasonal allergic rhinitis .\\n### Answer: ',\n",
       " 'raw_entities': {'INT': ['budesonide Turbuhaler', 'budesonide aqua'],\n",
       "  'PAR': ['seasonal allergic rhinitis .'],\n",
       "  'OUT': []},\n",
       " 'id': '0'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f8f60a4-394c-4707-9ff9-672b8772aaa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T11:30:17.358138Z",
     "iopub.status.busy": "2023-10-27T11:30:17.357836Z",
     "iopub.status.idle": "2023-10-27T11:30:17.409240Z",
     "shell.execute_reply": "2023-10-27T11:30:17.408614Z",
     "shell.execute_reply.started": "2023-10-27T11:30:17.358116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2076 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "top_5 = defaultdict(list)\n",
    "\n",
    "for i,t_sent in enumerate(tqdm(test_data)):\n",
    "    # if i==3:\n",
    "    tokenized_sents = tokenizer(t_sent, return_tensors='pt', padding=True, truncation=True).to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**tokenized_sents)[0]\n",
    "\n",
    "    cls_emb = last_hidden_state[:, 0, :]\n",
    "    cls_emb_1=cls_emb.cpu().numpy()\n",
    "    faiss.normalize_L2(cls_emb_1)\n",
    "    distance, index_l = index.search(cls_emb_1, 100)\n",
    "    index_list = index_l.reshape(-1,).tolist()\n",
    "    \n",
    "    for idx,ind in enumerate(index_list):\n",
    "        if idx == 5:\n",
    "            break\n",
    "        top_5[i].append(f_train[ind])\n",
    "    \n",
    "    break\n",
    "    \n",
    "    # for idx, ind in enumerate(index_l):\n",
    "    #     top_5[i].append("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "59a6d1de-a1ab-4cc3-aad8-9a9a7e701e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T12:58:16.444228Z",
     "iopub.status.busy": "2023-10-27T12:58:16.443669Z",
     "iopub.status.idle": "2023-10-27T12:58:16.447605Z",
     "shell.execute_reply": "2023-10-27T12:58:16.447047Z",
     "shell.execute_reply.started": "2023-10-27T12:58:16.444205Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_contxt(prompt,n_cntxt):\n",
    "    for i in n_cntxt:\n",
    "        prompt=prompt+\"input:{}\\n answer:{}\".format(i['input'],i['raw_entities'])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "618c8a40-e915-4bbc-9602-1a6cd631fdc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T13:03:06.381570Z",
     "iopub.status.busy": "2023-10-27T13:03:06.381085Z",
     "iopub.status.idle": "2023-10-27T13:03:06.387636Z",
     "shell.execute_reply": "2023-10-27T13:03:06.387059Z",
     "shell.execute_reply.started": "2023-10-27T13:03:06.381548Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2076 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "instrction_txt=\"You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT.\"  \n",
    "for idx,smple in enumerate(tqdm(f_test)):\n",
    "    prompt_txt=\"{}\\n\".format(instrction_txt)\n",
    "    cntxt=top_5[idx][:1]\n",
    "    prompt_n=get_contxt(prompt_txt,cntxt)\n",
    "    prompt_n=prompt_n+\"\\ninput:{}\\n answer: \".format(smple['input'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a6cb5c9a-eeb4-4ef1-b0e7-90b853681cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T13:03:08.161558Z",
     "iopub.status.busy": "2023-10-27T13:03:08.161012Z",
     "iopub.status.idle": "2023-10-27T13:03:08.165650Z",
     "shell.execute_reply": "2023-10-27T13:03:08.165117Z",
     "shell.execute_reply.started": "2023-10-27T13:03:08.161537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT.\\ninput:Comparison of ranitidine and lansoprazole in short-term low-dose triple therapy for Helicobacter pylori infection .\\n answer:{'INT': ['ranitidine', 'lansoprazole'], 'PAR': [], 'OUT': ['Comparison']}\\ninput:Comparison of budesonide Turbuhaler with budesonide aqua in the treatment of seasonal allergic rhinitis .\\n answer: \""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ec5f44f-fb26-49d3-ab9b-87ec53dd7710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T12:34:25.480890Z",
     "iopub.status.busy": "2023-10-27T12:34:25.480111Z",
     "iopub.status.idle": "2023-10-27T12:34:25.486210Z",
     "shell.execute_reply": "2023-10-27T12:34:25.485672Z",
     "shell.execute_reply.started": "2023-10-27T12:34:25.480865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Comparison of ranitidine and lansoprazole in short-term low-dose triple therapy for Helicobacter pylori infection .',\n",
       "  'output': 'INT: ranitidine, lansoprazole\\nPAR: \\nOUT: Comparison\\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of ranitidine and lansoprazole in short-term low-dose triple therapy for Helicobacter pylori infection .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['ranitidine', 'lansoprazole'],\n",
       "   'PAR': [],\n",
       "   'OUT': ['Comparison']},\n",
       "  'id': '1'},\n",
       " {'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Comparison of high and low dose of the inhaled steroid , budesonide , as an initial treatment in newly detected asthma .',\n",
       "  'output': 'INT: inhaled steroid , budesonide\\nPAR: asthma\\nOUT: \\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of high and low dose of the inhaled steroid , budesonide , as an initial treatment in newly detected asthma .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['inhaled steroid , budesonide'],\n",
       "   'PAR': ['asthma'],\n",
       "   'OUT': []},\n",
       "  'id': '1545'},\n",
       " {'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Comparison of tropisetron and granisetron in the control of nausea and vomiting in children receiving combined cancer chemotherapy .',\n",
       "  'output': 'INT: tropisetron and granisetron\\nPAR: children, cancer chemotherapy\\nOUT: nausea and vomiting\\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of tropisetron and granisetron in the control of nausea and vomiting in children receiving combined cancer chemotherapy .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['tropisetron and granisetron'],\n",
       "   'PAR': ['children', 'cancer chemotherapy'],\n",
       "   'OUT': ['nausea and vomiting']},\n",
       "  'id': '2895'},\n",
       " {'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Comparison of the efficacy of fluoxetine alone vs. fluoxetine plus local lidocaine ointment in the treatment of premature ejaculation .',\n",
       "  'output': 'INT: fluoxetine alone, fluoxetine, local lidocaine ointment\\nPAR: premature ejaculation\\nOUT: \\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of the efficacy of fluoxetine alone vs. fluoxetine plus local lidocaine ointment in the treatment of premature ejaculation .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['fluoxetine alone',\n",
       "    'fluoxetine',\n",
       "    'local lidocaine ointment'],\n",
       "   'PAR': ['premature ejaculation'],\n",
       "   'OUT': []},\n",
       "  'id': '2146'},\n",
       " {'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Efficacy and safety of two different testosterone undecanoate formulations in hypogonadal men with metabolic syndrome .',\n",
       "  'output': 'INT: two different testosterone undecanoate formulations\\nPAR: hypogonadal men, metabolic syndrome\\nOUT: \\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Efficacy and safety of two different testosterone undecanoate formulations in hypogonadal men with metabolic syndrome .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['two different testosterone undecanoate formulations'],\n",
       "   'PAR': ['hypogonadal men', 'metabolic syndrome'],\n",
       "   'OUT': []},\n",
       "  'id': '18159'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffe0d8d2-81e5-410a-b0be-a36aea976e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T11:55:12.766590Z",
     "iopub.status.busy": "2023-10-27T11:55:12.765955Z",
     "iopub.status.idle": "2023-10-27T11:55:12.770437Z",
     "shell.execute_reply": "2023-10-27T11:55:12.769958Z",
     "shell.execute_reply.started": "2023-10-27T11:55:12.766566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smple['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "241e3fe8-ef79-4838-b15c-75dc1c2cac06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T11:33:11.129184Z",
     "iopub.status.busy": "2023-10-27T11:33:11.128528Z",
     "iopub.status.idle": "2023-10-27T11:33:11.133978Z",
     "shell.execute_reply": "2023-10-27T11:33:11.133410Z",
     "shell.execute_reply.started": "2023-10-27T11:33:11.129160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Comparison of ranitidine and lansoprazole in short-term low-dose triple therapy for Helicobacter pylori infection .',\n",
       "  'output': 'INT: ranitidine, lansoprazole\\nPAR: \\nOUT: Comparison\\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of ranitidine and lansoprazole in short-term low-dose triple therapy for Helicobacter pylori infection .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['ranitidine', 'lansoprazole'],\n",
       "   'PAR': [],\n",
       "   'OUT': ['Comparison']},\n",
       "  'id': '1'},\n",
       " {'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Comparison of high and low dose of the inhaled steroid , budesonide , as an initial treatment in newly detected asthma .',\n",
       "  'output': 'INT: inhaled steroid , budesonide\\nPAR: asthma\\nOUT: \\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of high and low dose of the inhaled steroid , budesonide , as an initial treatment in newly detected asthma .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['inhaled steroid , budesonide'],\n",
       "   'PAR': ['asthma'],\n",
       "   'OUT': []},\n",
       "  'id': '1545'},\n",
       " {'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Comparison of tropisetron and granisetron in the control of nausea and vomiting in children receiving combined cancer chemotherapy .',\n",
       "  'output': 'INT: tropisetron and granisetron\\nPAR: children, cancer chemotherapy\\nOUT: nausea and vomiting\\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of tropisetron and granisetron in the control of nausea and vomiting in children receiving combined cancer chemotherapy .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['tropisetron and granisetron'],\n",
       "   'PAR': ['children', 'cancer chemotherapy'],\n",
       "   'OUT': ['nausea and vomiting']},\n",
       "  'id': '2895'},\n",
       " {'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Comparison of the efficacy of fluoxetine alone vs. fluoxetine plus local lidocaine ointment in the treatment of premature ejaculation .',\n",
       "  'output': 'INT: fluoxetine alone, fluoxetine, local lidocaine ointment\\nPAR: premature ejaculation\\nOUT: \\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Comparison of the efficacy of fluoxetine alone vs. fluoxetine plus local lidocaine ointment in the treatment of premature ejaculation .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['fluoxetine alone',\n",
       "    'fluoxetine',\n",
       "    'local lidocaine ointment'],\n",
       "   'PAR': ['premature ejaculation'],\n",
       "   'OUT': []},\n",
       "  'id': '2146'},\n",
       " {'instruction': 'You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT',\n",
       "  'input': 'Efficacy and safety of two different testosterone undecanoate formulations in hypogonadal men with metabolic syndrome .',\n",
       "  'output': 'INT: two different testosterone undecanoate formulations\\nPAR: hypogonadal men, metabolic syndrome\\nOUT: \\n',\n",
       "  'source': '### Task: You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT\\n### Input: Efficacy and safety of two different testosterone undecanoate formulations in hypogonadal men with metabolic syndrome .\\n### Answer: ',\n",
       "  'raw_entities': {'INT': ['two different testosterone undecanoate formulations'],\n",
       "   'PAR': ['hypogonadal men', 'metabolic syndrome'],\n",
       "   'OUT': []},\n",
       "  'id': '18159'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top_5[0]\n",
    "\"I have provided some examples for you to consider while predicting your answer. Make sure to analyze the text and identify the words that correspond to the given entities. Your response should include all relevant words for each entity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d79e14-6276-4e3d-ba1f-6503af1a7e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-29T05:56:26.641256Z",
     "iopub.status.busy": "2023-10-29T05:56:26.640961Z",
     "iopub.status.idle": "2023-10-29T06:04:34.087530Z",
     "shell.execute_reply": "2023-10-29T06:04:34.086889Z",
     "shell.execute_reply.started": "2023-10-29T05:56:26.641234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32671c0458a401a989da76f646ccb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5262607335d34439b12c27cdca5fc1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00003.bin:   0%|          | 0.00/9.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a392fd4ecb4d4be1ad0269ba8ce77edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00003.bin:   0%|          | 0.00/9.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac58738db6f4901ab01f47022e845b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00003.bin:   0%|          | 0.00/7.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4574be60bac146aeb36eef4ba8dcfe7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2d645896fa44b0a826804e37647889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Universal-NER/UniNER-7B-all\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Universal-NER/UniNER-7B-all\",device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b9b19cd1-cc9b-49a6-98e9-68f95406e412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T13:00:43.272337Z",
     "iopub.status.busy": "2023-10-27T13:00:43.271758Z",
     "iopub.status.idle": "2023-10-27T13:01:04.317016Z",
     "shell.execute_reply": "2023-10-27T13:01:04.316317Z",
     "shell.execute_reply.started": "2023-10-27T13:00:43.272314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a658be7d0a4d469f5b6331e63878b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, T5ForConditionalGeneration, GenerationConfig\n",
    "from peft import PeftConfig, PeftModel\n",
    "import torch\n",
    "\n",
    "model_name = \"/notebooks/Cods_PICO/instruct-ner/instruction_ner/llama2-conll2003\"\n",
    "generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(model_name)\n",
    "base_model_name = peft_config.base_model_name_or_path\n",
    "\n",
    "hf_auth = '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'\n",
    "    \n",
    "models = {'llama': AutoModelForCausalLM, 't5': T5ForConditionalGeneration}\n",
    "\n",
    "model = models[\"llama\"].from_pretrained(\n",
    "    base_model_name,\n",
    "    # load_in_8bit=True,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    "\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,use_auth_token=hf_auth)\n",
    "\n",
    "model.eval()\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3f7d9daa-a6ca-41d0-87cf-ed1b6ea48a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T13:03:14.075844Z",
     "iopub.status.busy": "2023-10-27T13:03:14.075027Z",
     "iopub.status.idle": "2023-10-27T13:03:14.079782Z",
     "shell.execute_reply": "2023-10-27T13:03:14.079150Z",
     "shell.execute_reply.started": "2023-10-27T13:03:14.075822Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt_n, return_tensors=\"pt\", padding=True)[\"input_ids\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f15f8727-d3f3-4678-9300-5f9480cd80e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T13:03:15.244331Z",
     "iopub.status.busy": "2023-10-27T13:03:15.244056Z",
     "iopub.status.idle": "2023-10-27T13:03:19.972670Z",
     "shell.execute_reply": "2023-10-27T13:03:19.971960Z",
     "shell.execute_reply.started": "2023-10-27T13:03:15.244311Z"
    }
   },
   "outputs": [],
   "source": [
    "extracted_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    generation_output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                generation_config=generation_config,\n",
    "                return_dict_in_generate=True,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "    for s in generation_output.sequences:\n",
    "            string_output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "            # extracted_list.append(extract_classes(string_output, ENTITY_TYPES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b603d127-961b-45e3-b6b5-434dfeccf08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T13:03:22.990881Z",
     "iopub.status.busy": "2023-10-27T13:03:22.990069Z",
     "iopub.status.idle": "2023-10-27T13:03:22.993967Z",
     "shell.execute_reply": "2023-10-27T13:03:22.993431Z",
     "shell.execute_reply.started": "2023-10-27T13:03:22.990859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are solving the NER problem. Extract from the text words related to each of the following entities: INT,PAR,OUT.\n",
      "input:Comparison of ranitidine and lansoprazole in short-term low-dose triple therapy for Helicobacter pylori infection .\n",
      " answer:{'INT': ['ranitidine', 'lansoprazole'], 'PAR': [], 'OUT': ['Comparison']}\n",
      "input:Comparison of budesonide Turbuhaler with budesonide aqua in the treatment of seasonal allergic rhinitis .\n",
      " answer: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(string_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd07c5-9002-4bc0-bf2e-0ae75d4cc94e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
